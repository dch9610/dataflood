{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 수작업 한 침수 및 비침수 (지리 동 )데이터와 강수 데이터 병합\n",
    "여기서 이제 동 및 코드까지 결합했지만 불완전했던 busan_flood_base에서 <br>\n",
    "지리데이터와 동 데이터를 수작업으로 작업 한 busan_flood_geo데이터를 가져와서 사용한다.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#원래\n",
    "#busan_flood_geo = pd.read_csv('../data/processing_data/1st/busan_flood_geo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "busan_flood_geo = pd.read_csv('../data/processing_data/1st/busan_flood_geo_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#필요한 컬럼 추출 및 컬럼명 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "busan_flood_geo = busan_flood_geo.drop(columns=['FLUD_CAUSE', 'F_DSSTR_NM', 'F_CUE_DTL',\n",
    "       'WRITNG_YM', 'FLUD_DPWT', 'DMG_AMOUNT', \n",
    "        'FLUD_WAL', 'CITY',  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "busan_flood_geo.rename(columns={\"FLUD_DPWT.1\":\"FLUD_DPWT\",\"F_DSTRC_NM\":\"DISTRICT\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_rain = pd.read_csv('../data/processing_data/1st/busan_rain_data_mod.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEQ 기준으로 inner 병합\n",
    "BF_TR = pd.merge(busan_flood_geo, time_rain, how='inner', on = 'SEQ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BF_TR = BF_TR.drop(columns='ADM_CD_y')\n",
    "BF_TR.rename(columns={'ADM_CD_x' : 'ADM_CD'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.시간당 최대 강우일 때만 침수심 남기고 모두 0으로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_list = busan_flood_geo['SEQ'].unique()\n",
    "for seq in SEQ_list:\n",
    "    BF_TR.loc[(BF_TR[\"SEQ\"]==seq) & (BF_TR[\"HOUR_RAINFALL\"]!=BF_TR[BF_TR[\"SEQ\"]==seq]['HOUR_RAINFALL'].max()),\"FLUD_DPWT\"]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BF_TR.to_csv('../data/processing_data/2nd/busan_flood_geo_rain.csv',index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결론)\n",
    "만든거 진서형 데이터에서 부산침수지역정보_시간당강우xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#원래\n",
    "#busan_unflood_geo = pd.read_csv('../data/processing_data/1st/busan_Unflood_geo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "busan_unflood_geo = pd.read_csv('../data/processing_data/1st/busan_Unflood_geo_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "busan_unflood_geo = pd.merge(busan_unflood_geo,time_rain, how='inner', on='SEQ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "busan_unflood_geo = busan_unflood_geo.drop(columns='ADM_CD_y')\n",
    "busan_unflood_geo.rename(columns={'ADM_CD_x':'ADM_CD'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "busan_unflood_geo.to_csv('../data/processing_data/2nd/busan_Unflood_geo_rain.csv',index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결론) 만든거 : 부산비침수지역정보_시간당강우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slope_weight(slope_info):\n",
    "    weight_data = slope_info.copy()\n",
    "    for idx,col in enumerate(slope_info):\n",
    "        if col <= 15:\n",
    "            weight_data[idx] = col / (46)\n",
    "        elif col > 15 and col <= 35:\n",
    "            weight_data[idx] = col / (18 * 2**2)\n",
    "        elif col > 35 and col <= 60:\n",
    "            weight_data[idx] = col / (17 * 3**2)\n",
    "        elif col > 60 and col <= 80:\n",
    "            weight_data[idx] = col / (11 * 4**2)\n",
    "        elif col > 80:\n",
    "            weight_data[idx] = col / (6.28 * 5**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_weight(high_info):\n",
    "    weight_data = high_info.copy()\n",
    "    for idx,col in enumerate(high_info):\n",
    "        if col <= 20:\n",
    "            weight_data[idx] = col / (79.62 / 1**2)\n",
    "        elif col > 20 and col <= 40:\n",
    "            weight_data[idx] = col / (10.18 / 2**2)\n",
    "        elif col > 40 and col <= 60:\n",
    "            weight_data[idx] = col / (4.63 / 3**2)\n",
    "        elif col > 60 and col <= 80:\n",
    "            weight_data[idx] = col / (2.78 / 4**2)\n",
    "        elif col > 80:\n",
    "            weight_data[idx] = col / (2.78 / 5**2)\n",
    "    return weight_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rain_weight(rain_info):\n",
    "    weight_data = rain_info.copy()\n",
    "    for idx,col in enumerate(rain_info):\n",
    "        if col <= 15:\n",
    "            weight_data[idx] = col / (46)\n",
    "        elif col > 15 and col <= 35:\n",
    "            weight_data[idx] = col / (18 * 2**2)\n",
    "        elif col > 35 and col <= 60:\n",
    "            weight_data[idx] = col / (17 * 3**2)\n",
    "        elif col > 60 and col <= 80:\n",
    "            weight_data[idx] = col / (11 * 4**2)\n",
    "        elif col > 80:\n",
    "            weight_data[idx] = col / (6.28 * 5**2)\n",
    "    return weight_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "BF_TR['Hourly_Rainfall_Weight'] = rain_weight(BF_TR['HOUR_RAINFALL'])\n",
    "BF_TR['HIGH_Weight'] = high_weight(BF_TR['HIGH'])\n",
    "BF_TR['SLOPE_AVG_Weight'] = slope_weight(BF_TR['SLOPE_AVG'])\n",
    "\n",
    "busan_unflood_geo['Hourly_Rainfall_Weight'] = rain_weight(busan_unflood_geo['HOUR_RAINFALL'])\n",
    "busan_unflood_geo['HIGH_Weight'] = high_weight(busan_unflood_geo['HIGH'])\n",
    "busan_unflood_geo['SLOPE_AVG_Weight'] = slope_weight(busan_unflood_geo['SLOPE_AVG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "BF_TR.to_csv('../data/processing_data/2nd/busan_flood_weight.csv',index=False, encoding='utf-8')\n",
    "busan_unflood_geo.to_csv('../data/processing_data/2nd/busan_Unflood_weight.csv',index=False,encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
