{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 필요 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                                          #데이터 분석 라이브러리\n",
    "from sklearn.decomposition import PCA                        #주성분 분석 라이브러리\n",
    "import numpy as np                                           # 계산 라이브러리\n",
    "from sklearn.preprocessing import MinMaxScaler               # 최소 최대 0~1 범위로 변환을 위한 라이브러리\n",
    "\n",
    "from sklearn.model_selection import train_test_split         # 데이터 분할 라이브러리\n",
    "from sklearn.model_selection import cross_validate           # Kfold 라이브러리\n",
    "from sklearn.model_selection import cross_val_score          # Kfold 라이브러리\n",
    "from sklearn.model_selection import StratifiedKFold          # Kfold 라이브러리\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier           # KNN 라이브러리\n",
    "from sklearn.svm import SVC                                  # SVM Classifier 라이브러리\n",
    "from sklearn.tree import DecisionTreeClassifier              # 결정나무분류 라이브러리\n",
    "from sklearn.linear_model import LogisticRegression          # 로지스틱 회귀 라이브러리\n",
    "from bayes_opt import BayesianOptimization                   # 베이시안 라이브러리   \n",
    "\n",
    "\n",
    "from sklearn.metrics import make_scorer                      # 평가용 라이브러리\n",
    "from sklearn.metrics import f1_score                         # f1  라이브러리\n",
    "from sklearn.metrics import accuracy_score                   # accuracy 라이브러리 \n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt                              # 그래프 라이브러리\n",
    "from sklearn.ensemble import VotingClassifier                # 보팅 앙상블 라이브러리\n",
    "import seaborn as sns                                        # boxplot 을 위한 라이브러리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "File = pd.read_csv(\"./Weighted_data_nonscale.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Floodfile = File.drop(['Unnamed: 0','FLOOD'], axis = 1)\n",
    "Floodclass = File['FLOOD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PUMP_RATIO</th>\n",
       "      <th>Hourly_Rainfall_Weight</th>\n",
       "      <th>Impervious_Surface_Weight</th>\n",
       "      <th>SLOPE_AVG_Weight</th>\n",
       "      <th>HIGH_Weight</th>\n",
       "      <th>F_WEIGHT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.115226e-07</td>\n",
       "      <td>0.104348</td>\n",
       "      <td>0.467342</td>\n",
       "      <td>0.599952</td>\n",
       "      <td>0.045968</td>\n",
       "      <td>0.075019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.115226e-07</td>\n",
       "      <td>0.208696</td>\n",
       "      <td>0.467342</td>\n",
       "      <td>0.599952</td>\n",
       "      <td>0.045968</td>\n",
       "      <td>0.075019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.115226e-07</td>\n",
       "      <td>0.259722</td>\n",
       "      <td>0.467342</td>\n",
       "      <td>0.599952</td>\n",
       "      <td>0.045968</td>\n",
       "      <td>0.075019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.115226e-07</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.467342</td>\n",
       "      <td>2.699784</td>\n",
       "      <td>0.072218</td>\n",
       "      <td>0.075019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.115226e-07</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.467342</td>\n",
       "      <td>2.699784</td>\n",
       "      <td>0.072218</td>\n",
       "      <td>0.075019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>1.364381e-08</td>\n",
       "      <td>0.573248</td>\n",
       "      <td>1.156156</td>\n",
       "      <td>7.040000</td>\n",
       "      <td>115.950324</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>1.364381e-08</td>\n",
       "      <td>0.573248</td>\n",
       "      <td>1.156156</td>\n",
       "      <td>21.608643</td>\n",
       "      <td>13.159136</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>1.364381e-08</td>\n",
       "      <td>0.573248</td>\n",
       "      <td>1.156156</td>\n",
       "      <td>12.147570</td>\n",
       "      <td>0.066817</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>1.364381e-08</td>\n",
       "      <td>0.573248</td>\n",
       "      <td>1.156156</td>\n",
       "      <td>21.608643</td>\n",
       "      <td>0.061794</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>1.364381e-08</td>\n",
       "      <td>0.573248</td>\n",
       "      <td>1.156156</td>\n",
       "      <td>21.608643</td>\n",
       "      <td>448.115108</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>796 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PUMP_RATIO  Hourly_Rainfall_Weight  Impervious_Surface_Weight  \\\n",
       "0    4.115226e-07                0.104348                   0.467342   \n",
       "1    4.115226e-07                0.208696                   0.467342   \n",
       "2    4.115226e-07                0.259722                   0.467342   \n",
       "3    4.115226e-07                0.010870                   0.467342   \n",
       "4    4.115226e-07                0.108696                   0.467342   \n",
       "..            ...                     ...                        ...   \n",
       "791  1.364381e-08                0.573248                   1.156156   \n",
       "792  1.364381e-08                0.573248                   1.156156   \n",
       "793  1.364381e-08                0.573248                   1.156156   \n",
       "794  1.364381e-08                0.573248                   1.156156   \n",
       "795  1.364381e-08                0.573248                   1.156156   \n",
       "\n",
       "     SLOPE_AVG_Weight  HIGH_Weight  F_WEIGHT  \n",
       "0            0.599952     0.045968  0.075019  \n",
       "1            0.599952     0.045968  0.075019  \n",
       "2            0.599952     0.045968  0.075019  \n",
       "3            2.699784     0.072218  0.075019  \n",
       "4            2.699784     0.072218  0.075019  \n",
       "..                ...          ...       ...  \n",
       "791          7.040000   115.950324  0.016667  \n",
       "792         21.608643    13.159136  0.016667  \n",
       "793         12.147570     0.066817  0.016667  \n",
       "794         21.608643     0.061794  0.016667  \n",
       "795         21.608643   448.115108  0.016667  \n",
       "\n",
       "[796 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Floodfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# minmaxscaler\n",
    "## data scale 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(Floodfile)\n",
    "Floodfile = scaler.transform(Floodfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=4) # 주성분을 몇개로 할지 결정\n",
    "printcipalComponents = pca.fit_transform(Floodfile)\n",
    "Floodfile = pd.DataFrame(data=printcipalComponents, columns = ['principal component1', 'principal component2','principal component3', 'principal component4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>principal component1</th>\n",
       "      <th>principal component2</th>\n",
       "      <th>principal component3</th>\n",
       "      <th>principal component4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.011940</td>\n",
       "      <td>0.141868</td>\n",
       "      <td>-0.346867</td>\n",
       "      <td>0.120298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.034011</td>\n",
       "      <td>0.137298</td>\n",
       "      <td>-0.260972</td>\n",
       "      <td>-0.035119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.044803</td>\n",
       "      <td>0.135063</td>\n",
       "      <td>-0.218968</td>\n",
       "      <td>-0.111119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.003553</td>\n",
       "      <td>0.115147</td>\n",
       "      <td>-0.344956</td>\n",
       "      <td>0.306535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.024245</td>\n",
       "      <td>0.110863</td>\n",
       "      <td>-0.264429</td>\n",
       "      <td>0.160832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>-0.459173</td>\n",
       "      <td>0.036658</td>\n",
       "      <td>0.376578</td>\n",
       "      <td>-0.516097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>-0.532985</td>\n",
       "      <td>-0.169149</td>\n",
       "      <td>0.914837</td>\n",
       "      <td>-0.197536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>-0.481033</td>\n",
       "      <td>-0.029302</td>\n",
       "      <td>0.558410</td>\n",
       "      <td>-0.410303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>-0.532326</td>\n",
       "      <td>-0.168134</td>\n",
       "      <td>0.913709</td>\n",
       "      <td>-0.198502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>-0.554868</td>\n",
       "      <td>-0.202886</td>\n",
       "      <td>0.952283</td>\n",
       "      <td>-0.165452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>796 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     principal component1  principal component2  principal component3  \\\n",
       "0               -0.011940              0.141868             -0.346867   \n",
       "1               -0.034011              0.137298             -0.260972   \n",
       "2               -0.044803              0.135063             -0.218968   \n",
       "3               -0.003553              0.115147             -0.344956   \n",
       "4               -0.024245              0.110863             -0.264429   \n",
       "..                    ...                   ...                   ...   \n",
       "791             -0.459173              0.036658              0.376578   \n",
       "792             -0.532985             -0.169149              0.914837   \n",
       "793             -0.481033             -0.029302              0.558410   \n",
       "794             -0.532326             -0.168134              0.913709   \n",
       "795             -0.554868             -0.202886              0.952283   \n",
       "\n",
       "     principal component4  \n",
       "0                0.120298  \n",
       "1               -0.035119  \n",
       "2               -0.111119  \n",
       "3                0.306535  \n",
       "4                0.160832  \n",
       "..                    ...  \n",
       "791             -0.516097  \n",
       "792             -0.197536  \n",
       "793             -0.410303  \n",
       "794             -0.198502  \n",
       "795             -0.165452  \n",
       "\n",
       "[796 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Floodfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data split\n",
    "## 8 : 2 으로 training 과 test 구분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(Floodfile, Floodclass , test_size=0.2, random_state=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skfolds=StratifiedKFold(n_splits=3, random_state=400 ,shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BayesianOptimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_search_point = {'k': (3,50), 'leaf': (1,50)}\n",
    "\n",
    "gp_params = {\"alpha\":1e-10}\n",
    "scores_all = []\n",
    "k_all = []\n",
    "leaf_all=[]\n",
    "\n",
    "def KNN_opt(k,leaf):\n",
    "    cvscores = []\n",
    "    \n",
    "    for train_index, val_index in skfolds.split(x_train, y_train):\n",
    "#         print(train_index)\n",
    "#         print(val_index)\n",
    "        x_skftrain, x_val = x_train.values[train_index], x_train.values[val_index]\n",
    "        Y_skftrain, Y_val = np.array(y_train)[train_index],np.array(y_train)[val_index]\n",
    "        \n",
    "        KNNmodel = KNeighborsClassifier(n_neighbors = int(k),weights = 'distance', leaf_size= leaf ) # KNN  \n",
    "        \n",
    "        KNNmodel2 = KNNmodel.fit(x_skftrain,Y_skftrain)      # 모델학습\n",
    "        y_pred = KNNmodel2.predict(x_val)                    # 예측\n",
    "\n",
    "        report = f1_score(Y_val, y_pred, average='weighted') # F1\n",
    "#         report = accuracy_score(Y_val, y_pred)             # accuracy\n",
    "        cvscores.append(report)\n",
    "    \n",
    "    \n",
    "    scores_all.append(np.mean(cvscores))\n",
    "    k_all.append(int(k))\n",
    "#     leaf_all.append(int(leaf))\n",
    "    \n",
    "    return np.mean(cvscores)\n",
    "\n",
    "result = BayesianOptimization(KNN_opt, KNN_search_point,    random_state=10,    verbose=2) \n",
    "result.maximize(acq='ucb',n_iter=15, kappa=2.576, init_points=1 , **gp_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(k_all, scores_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_search_point = {'k': (1,50), 'gamma': (0.001,20)}\n",
    "\n",
    "gp_params = {\"alpha\":1e-10}\n",
    "scores_all = []\n",
    "k_all = []\n",
    "gamma_all = []\n",
    "def SVM_opt(k,gamma):\n",
    "    cvscores = []\n",
    "    \n",
    "    for train_index, val_index in skfolds.split(x_train, y_train):\n",
    "        x_skftrain, x_val = x_train.values[train_index],x_train.values[val_index]\n",
    "        Y_skftrain, Y_val = np.array(y_train)[train_index],np.array(y_train)[val_index]\n",
    "\n",
    "        SVMmodel = SVC( C= int(k) , kernel='rbf' , probability = True, gamma = gamma ) # SVM  \n",
    "        \n",
    "        SVMmodel2 = SVMmodel.fit(x_skftrain,Y_skftrain)      # 모델학습\n",
    "        y_pred = SVMmodel2.predict(x_val)                    # 예측\n",
    "\n",
    "        report = f1_score(Y_val, y_pred, average='weighted') # F1\n",
    "#         report = accuracy_score(Y_val, y_pred)             # accuracy\n",
    "        cvscores.append(report)\n",
    "    \n",
    "    scores_all.append(np.mean(cvscores))\n",
    "    k_all.append(int(k))\n",
    "    return np.mean(cvscores)\n",
    "\n",
    "result = BayesianOptimization(SVM_opt, SVM_search_point, random_state=10, verbose=2) \n",
    "result.maximize(acq='ucb',n_iter=15, kappa=2.576, init_points=1 , **gp_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_search_point = {'k': (1,50)}\n",
    "\n",
    "gp_params = {\"alpha\":1e-10}\n",
    "scores_all = []\n",
    "k_all = []\n",
    "gamma_all = []\n",
    "def SVM_opt(k):\n",
    "    cvscores = []\n",
    "    \n",
    "    for train_index, val_index in skfolds.split(x_train, y_train):\n",
    "        x_skftrain, x_val = x_train.values[train_index],x_train.values[val_index]\n",
    "        Y_skftrain, Y_val = np.array(y_train)[train_index],np.array(y_train)[val_index]\n",
    "\n",
    "        SVMmodel = SVC( C= int(k) , kernel='poly' , probability = True ) # SVM  \n",
    "        \n",
    "        SVMmodel2 = SVMmodel.fit(x_skftrain,Y_skftrain)      # 모델학습\n",
    "        y_pred = SVMmodel2.predict(x_val)                    # 예측\n",
    "\n",
    "        report = f1_score(Y_val, y_pred, average='weighted') # F1\n",
    "#         report = accuracy_score(Y_val, y_pred)             # accuracy\n",
    "        cvscores.append(report)\n",
    "    \n",
    "    scores_all.append(np.mean(cvscores))\n",
    "    k_all.append(int(k))\n",
    "    return np.mean(cvscores)\n",
    "\n",
    "result = BayesianOptimization(SVM_opt, SVM_search_point, random_state=10, verbose=2) \n",
    "result.maximize(acq='ucb',n_iter=15, kappa=2.576, init_points=1 , **gp_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(k_all, scores_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_search_point = { 'k': (1,30), 'leaf' : ( 2, 30), 'split': (2,30) }\n",
    "\n",
    "gp_params = {\"alpha\":1e-10}\n",
    "scores_all = []\n",
    "k_all = []\n",
    "leaf_all = []\n",
    "split_all = []\n",
    "\n",
    "def DT_opt(k,leaf,split):\n",
    "    cvscores = []\n",
    "    \n",
    "    for train_index, val_index in skfolds.split(x_train, y_train):\n",
    "        x_skftrain, x_val = x_train.values[train_index],x_train.values[val_index]\n",
    "        Y_skftrain, Y_val = np.array(y_train)[train_index],np.array(y_train)[val_index]\n",
    "\n",
    "        DTmodel = DecisionTreeClassifier(criterion='gini',\n",
    "                                         max_depth=int(k),              # 트리의 최대 깊이\n",
    "                                         min_samples_leaf= int(leaf),\n",
    "                                         min_samples_split= int(split)) #DT  \n",
    "        \n",
    "        \n",
    "        DTmodel2 = DTmodel.fit(x_skftrain,Y_skftrain)      # 모델학습\n",
    "        y_pred = DTmodel2.predict(x_val)                    # 예측\n",
    "\n",
    "        report = f1_score(Y_val, y_pred, average='weighted') # F1\n",
    "#         report = accuracy_score(Y_val, y_pred)             # accuracy\n",
    "        cvscores.append(report)\n",
    "    \n",
    "    scores_all.append(np.mean(cvscores))\n",
    "    k_all.append(int(k))\n",
    "    leaf_all.append(int(leaf))\n",
    "    split_all.append(split)\n",
    "\n",
    "    \n",
    "    return np.mean(cvscores)\n",
    "\n",
    "result = BayesianOptimization(DT_opt, DT_search_point, random_state=10, verbose=2) \n",
    "result.maximize(acq='ucb',n_iter=15, kappa=2.576, init_points=1 , **gp_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(k_all, scores_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_search_point = { 'k': (1,50)}\n",
    "\n",
    "gp_params = {\"alpha\":1e-10}\n",
    "scores_all = []\n",
    "k_all = []\n",
    "\n",
    "def LR_opt(k):\n",
    "    cvscores = []\n",
    "    \n",
    "    for train_index, val_index in skfolds.split(x_train, y_train):\n",
    "        x_skftrain, x_val = x_train.values[train_index],x_train.values[val_index]\n",
    "        Y_skftrain, Y_val = np.array(y_train)[train_index],np.array(y_train)[val_index]\n",
    "\n",
    "        LRmodel = LogisticRegression(C= int(k) , multi_class= 'auto') #LR  \n",
    "        \n",
    "        \n",
    "        LRmodel2 = LRmodel.fit(x_skftrain,Y_skftrain)      # 모델학습\n",
    "        y_pred = LRmodel2.predict(x_val)                    # 예측\n",
    "\n",
    "        report = f1_score(Y_val, y_pred, average='weighted') # F1\n",
    "#         report = accuracy_score(Y_val, y_pred)             # accuracy\n",
    "        cvscores.append(report)\n",
    "    \n",
    "    scores_all.append(np.mean(cvscores))\n",
    "    k_all.append(int(k))\n",
    "    \n",
    "    return np.mean(cvscores)\n",
    "\n",
    "result = BayesianOptimization(LR_opt, LR_search_point, random_state=10, verbose=2) \n",
    "result.maximize(acq='ucb',n_iter=15, kappa=2.576, init_points=1 , **gp_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(k_all, scores_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting ensemble\n",
    "## 사용 된 모델 : KNN, SVM, Decision Tree, Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_model = KNeighborsClassifier(n_neighbors = 21,weights = 'distance', leaf_size=49)\n",
    "\n",
    "SVM_model = SVC( C= 29 , kernel='rbf' , probability = True , gamma = 30 )\n",
    "\n",
    "DT_model = DecisionTreeClassifier(criterion='gini', max_depth=28, min_samples_leaf= 5, min_samples_split= 2)\n",
    "\n",
    "LR_model = LogisticRegression(C= 5, multi_class= 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_model = KNeighborsClassifier()\n",
    "\n",
    "SVM_model = SVC(probability = True )\n",
    "\n",
    "DT_model = DecisionTreeClassifier()\n",
    "\n",
    "LR_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble=VotingClassifier(\n",
    "        estimators=[('KNN',KNN_model),\n",
    "                   ('SVM',SVM_model),\n",
    "                   ('DT',DT_model),\n",
    "                   ('LR',LR_model)]\n",
    "        ,voting='soft')\n",
    "\n",
    "# Voting 모델 안에 각 모델들을 묶어주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_model.fit(x_train,y_train)\n",
    "SVM_model.fit(x_train,y_train)\n",
    "DT_model.fit(x_train,y_train)\n",
    "LR_model.fit(x_train,y_train)\n",
    "ensemble.fit(x_train,y_train)\n",
    "\n",
    "# 각 모델들을 데이터로 학습시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 교차검증 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKF = StratifiedKFold( n_splits = 3,  shuffle = True, random_state = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_scores=cross_validate(KNN_model, x_train, y_train, cv=SKF, scoring=make_scorer(f1_score))\n",
    "SVM_scores=cross_validate(SVM_model, x_train, y_train, cv=SKF, scoring=make_scorer(f1_score))\n",
    "DT_scores=cross_validate(DT_model, x_train, y_train, cv=SKF, scoring=make_scorer(f1_score))\n",
    "LR_scores=cross_validate(LR_model, x_train, y_train, cv=SKF, scoring=make_scorer(f1_score))\n",
    "ensemble_scores=cross_validate(ensemble, x_train, y_train, cv=SKF, scoring=make_scorer(f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(KNN_scores)\n",
    "print(SVM_scores)\n",
    "print(DT_scores)\n",
    "print(LR_scores)\n",
    "print(ensemble_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_f1_score = KNN_scores[\"test_score\"].mean()\n",
    "SVN_f1_score = SVM_scores[\"test_score\"].mean()\n",
    "DT_f1_score = DT_scores[\"test_score\"].mean()\n",
    "LR_f1_score = LR_scores[\"test_score\"].mean()\n",
    "ensemble_f1_score = ensemble_scores[\"test_score\"].mean()\n",
    "\n",
    "\n",
    "print(\"f1_score: {0: .4f}\".format(KNN_f1_score))\n",
    "print(\"f1_score: {0: .4f}\".format(SVN_f1_score))\n",
    "print(\"f1_score: {0: .4f}\".format(DT_f1_score))\n",
    "print(\"f1_score: {0: .4f}\".format(LR_f1_score))\n",
    "print(\"f1_score: {0: .4f}\".format(ensemble_f1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결과 boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "names = []\n",
    "\n",
    "models = []\n",
    "models.append(('KNN', KNN_model))\n",
    "models.append(('SVM', SVM_model))\n",
    "models.append(('DT', DT_model))\n",
    "models.append(('LR', LR_model))\n",
    "models.append(('Voting',ensemble))\n",
    "\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = StratifiedKFold( n_splits = 3,  shuffle = True, random_state = 10)\n",
    "#     cv_results = cross_validate(ensemble, x_train, y_train, cv=SKF, scoring=make_scorer(f1_score))\n",
    "    cv_results = cross_val_score(ensemble, x_train, y_train, cv=SKF, scoring=make_scorer(f1_score))\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Classifier Comparison')\n",
    "ax= fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test 데이터 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_KNN = KNN_model.predict(x_test)\n",
    "pred_SVM = SVM_model.predict(x_test)\n",
    "pred_DT = DT_model.predict(x_test)\n",
    "pred_LR = LR_model.predict(x_test)\n",
    "\n",
    "# 각 모델들의 f1_score 파악을 위해 모델들 예측실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict= ensemble.predict(x_test)\n",
    "\n",
    "# 적용 모델인 Voting ensemble 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data 교차검증 boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "names = []\n",
    "\n",
    "models = []\n",
    "models.append(('KNN', KNN_model))\n",
    "models.append(('SVM', SVM_model))\n",
    "models.append(('DT', DT_model))\n",
    "models.append(('LR', LR_model))\n",
    "models.append(('Voting',ensemble))\n",
    "\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = StratifiedKFold( n_splits = 3,  shuffle = True, random_state = 10)\n",
    "#     cv_results = cross_validate(ensemble, x_train, y_train, cv=SKF, scoring=make_scorer(f1_score))\n",
    "    cv_results = cross_val_score(ensemble, x_test, y_test, cv=SKF, scoring=make_scorer(f1_score))\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Classifier Comparison')\n",
    "ax= fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020 년 사고사례 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "accident = pd.read_excel(\"초량동 지형 강우량.xlsx\")   # 초량지하차도 지형정보 와 당일 시간당 강우량 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['FLOOD'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-924922bc8799>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mBusanaccident\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccident\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SLOPE_L'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'SLOPE_H'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'FLOOD'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'MANHOLES_RATIO'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 불필요 컬럼제거\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mBusanaccidentclass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccident\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'FLOOD'\u001b[0m\u001b[1;33m]\u001b[0m                                                  \u001b[1;31m# 분류구분\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pcrmc\\desktop\\venv\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4167\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4168\u001b[0m             \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4169\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4170\u001b[0m         )\n\u001b[0;32m   4171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pcrmc\\desktop\\venv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3882\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3883\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3884\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3885\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3886\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pcrmc\\desktop\\venv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3916\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3917\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3918\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3919\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3920\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\pcrmc\\desktop\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5276\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5277\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5278\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5279\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5280\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['FLOOD'] not found in axis\""
     ]
    }
   ],
   "source": [
    "Busanaccident = accident.drop(['SLOPE_L','SLOPE_H','FLOOD','MANHOLES_RATIO'], axis = 1)  # 불필요 컬럼제거\n",
    "Busanaccidentclass = accident['FLOOD']                                                  # 분류구분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 가중치 주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Busanaccident.rename(columns={'R_W_SUM':'Hourly_Rainfall_Weight','HOUR_RAINFALL':'Hourly_Rainfall','IMP_SUR_RATIO':'Impervious_Surface',\n",
    "                              'IMP_W_SUM':'Impervious_Surface_Weight'},inplace=True)  # 컬럼명 수정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 강우량 가중치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,col in enumerate(Busanaccident['Hourly_Rainfall']):\n",
    "    if col <= 15:\n",
    "        Busanaccident['Hourly_Rainfall_Weight'][idx] = col / (46)\n",
    "    elif col > 15 and col <= 35:\n",
    "        Busanaccident['Hourly_Rainfall_Weight'][idx] = col / (18 * 2**2)\n",
    "    elif col > 35 and col <= 60:\n",
    "        Busanaccident['Hourly_Rainfall_Weight'][idx] = col / (17 * 3**2)\n",
    "    elif col > 60 and col <= 80:\n",
    "        Busanaccident['Hourly_Rainfall_Weight'][idx] = col / (11 * 4**2)\n",
    "    elif col > 80:\n",
    "        Busanaccident['Hourly_Rainfall_Weight'][idx] = col / (6.28 * 5**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 불투수면 가중치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,col in enumerate(Busanaccident['Impervious_Surface']):\n",
    "    if col <= 15:\n",
    "        Busanaccident['Impervious_Surface_Weight'][idx] = col / 6.66\n",
    "    elif col > 15 and col <= 25:\n",
    "        Busanaccident['Impervious_Surface_Weight'][idx] = col / (20 * 2)\n",
    "    elif col > 25 and col <= 40:\n",
    "        Busanaccident['Impervious_Surface_Weight'][idx] = col / (13.33 * 3)\n",
    "    elif col > 40 and col <= 55:\n",
    "        Busanaccident['Impervious_Surface_Weight'][idx] = col / (33.33 * 4)\n",
    "    elif col > 55:\n",
    "        Busanaccident['Impervious_Surface_Weight'][idx] = col / (26.67 * 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 경사도 가중치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Busanaccident['SLOPE_AVG_Weight'] = Busanaccident['SLOPE_AVG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,col in enumerate(Busanaccident['SLOPE_AVG']):\n",
    "    if col <= 10:\n",
    "        Busanaccident['SLOPE_AVG_Weight'][idx] = col / (41.67 / 5**2 )\n",
    "    elif col > 10 and col <= 15:\n",
    "        Busanaccident['SLOPE_AVG_Weight'][idx] = col / (25 / 4**2)\n",
    "    elif col > 15 and col <= 25:\n",
    "        Busanaccident['SLOPE_AVG_Weight'][idx] = col / (16.67 / 3**2)\n",
    "    elif col > 25 and col <= 50:\n",
    "        Busanaccident['SLOPE_AVG_Weight'][idx] = col / (8.33 / 2**2)\n",
    "    elif col > 50:\n",
    "        Busanaccident['SLOPE_AVG_Weight'][idx] = col / (8.33 / 1**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 고도 가중치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Busanaccident['HIGH_Weight'] = Busanaccident['HIGH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,col in enumerate(Busanaccident['HIGH']):\n",
    "    if col <= 20:\n",
    "        Busanaccident['HIGH_Weight'][idx] = col / (79.62 / 1**2)\n",
    "    elif col > 20 and col <= 40:\n",
    "        Busanaccident['HIGH_Weight'][idx] = col / (10.18 / 2**2)\n",
    "    elif col > 40 and col <= 60:\n",
    "        Busanaccident['HIGH_Weight'][idx] = col / (4.63 / 3**2)\n",
    "    elif col > 60 and col <= 80:\n",
    "        Busanaccident['HIGH_Weight'][idx] = col / (2.78 / 4**2)\n",
    "    elif col > 80:\n",
    "        Busanaccident['HIGH_Weight'][idx] = col / (2.78 / 5**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Busanaccident = Busanaccident.drop(['SLOPE_AVG','Impervious_Surface','Hourly_Rainfall','HIGH'], axis = 1)\n",
    "Busanaccident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(Busanaccident)\n",
    "Busanaccident = scaler.transform(Busanaccident)                         # sccler 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=4)\n",
    "printcipalComponents = pca.fit_transform(Busanaccident)\n",
    "Busanaccident = pd.DataFrame(data=printcipalComponents, columns = ['principal component1', 'principal component2','principal component3', 'principal component4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 예측값 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accident_predict= ensemble.predict(Busanaccident)                       # 위에서 학습된 모델 활용을 이용한 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accident_predict)                                                 # 예측값 확인"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
