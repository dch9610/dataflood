{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 필요 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                                          #데이터 분석 라이브러리\n",
    "from sklearn.decomposition import PCA                        #주성분 분석 라이브러리\n",
    "import numpy as np                                           # 계산 라이브러리\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler    # scale 라이브러리\n",
    "\n",
    "from sklearn.model_selection import train_test_split         # 데이터 분할 라이브러리\n",
    "from sklearn.model_selection import cross_validate           # Kfold 라이브러리\n",
    "from sklearn.model_selection import cross_val_score          # Kfold 라이브러리\n",
    "from sklearn.model_selection import StratifiedKFold          # Kfold 라이브러리\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier           # KNN 라이브러리\n",
    "from sklearn.svm import SVC                                  # SVM Classifier 라이브러리\n",
    "from sklearn.tree import DecisionTreeClassifier              # 결정나무분류 라이브러리\n",
    "from sklearn.linear_model import LogisticRegression          # 로지스틱 회귀 라이브러리\n",
    "from sklearn.ensemble import RandomForestClassifier          # 랜덤 포레스트 라이브러리\n",
    "from bayes_opt import BayesianOptimization                   # 베이시안 라이브러리   \n",
    "\n",
    "\n",
    "from sklearn.metrics import make_scorer                      # 평가용 라이브러리\n",
    "from sklearn.metrics import f1_score                         # f1  라이브러리\n",
    "from sklearn.metrics import accuracy_score                   # accuracy 라이브러리 \n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt                              # 그래프 라이브러리\n",
    "from sklearn.ensemble import VotingClassifier                # 보팅 앙상블 라이브러리\n",
    "import seaborn as sns                                        # boxplot 을 위한 라이브러리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "File = pd.read_csv(\"Weighted_data_nonscale_final.csv\")   # 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Floodfile = File.drop(['Unnamed: 0','FLOOD'], axis = 1)  # 필요 독립변수\n",
    "Floodclass = File['FLOOD']                                            # 종속 변수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PUMP_RATIO</th>\n",
       "      <th>Hourly_Rainfall_Weight</th>\n",
       "      <th>Impervious_Surface_Weight</th>\n",
       "      <th>SLOPE_AVG_Weight</th>\n",
       "      <th>HIGH_Weight</th>\n",
       "      <th>F_WEIGHT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.115226e-07</td>\n",
       "      <td>0.104348</td>\n",
       "      <td>0.467342</td>\n",
       "      <td>0.599952</td>\n",
       "      <td>0.045968</td>\n",
       "      <td>0.075019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.115226e-07</td>\n",
       "      <td>0.208696</td>\n",
       "      <td>0.467342</td>\n",
       "      <td>0.599952</td>\n",
       "      <td>0.045968</td>\n",
       "      <td>0.075019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.115226e-07</td>\n",
       "      <td>0.259722</td>\n",
       "      <td>0.467342</td>\n",
       "      <td>0.599952</td>\n",
       "      <td>0.045968</td>\n",
       "      <td>0.075019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.115226e-07</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.467342</td>\n",
       "      <td>2.699784</td>\n",
       "      <td>0.072218</td>\n",
       "      <td>0.075019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.115226e-07</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.467342</td>\n",
       "      <td>2.699784</td>\n",
       "      <td>0.072218</td>\n",
       "      <td>0.075019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>1.364381e-08</td>\n",
       "      <td>0.573248</td>\n",
       "      <td>1.156156</td>\n",
       "      <td>7.040000</td>\n",
       "      <td>115.950324</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>1.364381e-08</td>\n",
       "      <td>0.573248</td>\n",
       "      <td>1.156156</td>\n",
       "      <td>21.608643</td>\n",
       "      <td>13.159136</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>1.364381e-08</td>\n",
       "      <td>0.573248</td>\n",
       "      <td>1.156156</td>\n",
       "      <td>12.147570</td>\n",
       "      <td>0.066817</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>1.364381e-08</td>\n",
       "      <td>0.573248</td>\n",
       "      <td>1.156156</td>\n",
       "      <td>21.608643</td>\n",
       "      <td>0.061794</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>1.364381e-08</td>\n",
       "      <td>0.573248</td>\n",
       "      <td>1.156156</td>\n",
       "      <td>21.608643</td>\n",
       "      <td>448.115108</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>796 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PUMP_RATIO  Hourly_Rainfall_Weight  Impervious_Surface_Weight  \\\n",
       "0    4.115226e-07                0.104348                   0.467342   \n",
       "1    4.115226e-07                0.208696                   0.467342   \n",
       "2    4.115226e-07                0.259722                   0.467342   \n",
       "3    4.115226e-07                0.010870                   0.467342   \n",
       "4    4.115226e-07                0.108696                   0.467342   \n",
       "..            ...                     ...                        ...   \n",
       "791  1.364381e-08                0.573248                   1.156156   \n",
       "792  1.364381e-08                0.573248                   1.156156   \n",
       "793  1.364381e-08                0.573248                   1.156156   \n",
       "794  1.364381e-08                0.573248                   1.156156   \n",
       "795  1.364381e-08                0.573248                   1.156156   \n",
       "\n",
       "     SLOPE_AVG_Weight  HIGH_Weight  F_WEIGHT  \n",
       "0            0.599952     0.045968  0.075019  \n",
       "1            0.599952     0.045968  0.075019  \n",
       "2            0.599952     0.045968  0.075019  \n",
       "3            2.699784     0.072218  0.075019  \n",
       "4            2.699784     0.072218  0.075019  \n",
       "..                ...          ...       ...  \n",
       "791          7.040000   115.950324  0.016667  \n",
       "792         21.608643    13.159136  0.016667  \n",
       "793         12.147570     0.066817  0.016667  \n",
       "794         21.608643     0.061794  0.016667  \n",
       "795         21.608643   448.115108  0.016667  \n",
       "\n",
       "[796 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Floodfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# minmaxscaler\n",
    "## data scale 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(Floodfile)\n",
    "Floodfile = scaler.transform(Floodfile)  # data sclae 과정 -> minmaxscaler 를 통해 0~1의 값으로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=4)  # 주성분 분석 후 -> 주성분을 몇개로 할지 결정\n",
    "printcipalComponents = pca.fit_transform(Floodfile)  \n",
    "Floodfile = pd.DataFrame(data=printcipalComponents, columns = ['principal component1', 'principal component2','principal component3', 'principal component4'])\n",
    "# pca를 통해 나온 4가지 주성분을 독립변수로 사용하도록 데이터 변형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>principal component1</th>\n",
       "      <th>principal component2</th>\n",
       "      <th>principal component3</th>\n",
       "      <th>principal component4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.063927</td>\n",
       "      <td>-0.681744</td>\n",
       "      <td>0.053284</td>\n",
       "      <td>0.082002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.058611</td>\n",
       "      <td>-0.630972</td>\n",
       "      <td>0.127358</td>\n",
       "      <td>-0.069406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.056012</td>\n",
       "      <td>-0.606144</td>\n",
       "      <td>0.163581</td>\n",
       "      <td>-0.143445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.039158</td>\n",
       "      <td>-0.683262</td>\n",
       "      <td>0.053191</td>\n",
       "      <td>0.266411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.034175</td>\n",
       "      <td>-0.635663</td>\n",
       "      <td>0.122636</td>\n",
       "      <td>0.124467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>0.025624</td>\n",
       "      <td>0.696675</td>\n",
       "      <td>0.074157</td>\n",
       "      <td>-0.569671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>-0.171061</td>\n",
       "      <td>0.993761</td>\n",
       "      <td>0.527883</td>\n",
       "      <td>-0.238038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>-0.036974</td>\n",
       "      <td>0.794668</td>\n",
       "      <td>0.228558</td>\n",
       "      <td>-0.458647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>-0.170018</td>\n",
       "      <td>0.992751</td>\n",
       "      <td>0.527118</td>\n",
       "      <td>-0.238898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>-0.205687</td>\n",
       "      <td>1.027325</td>\n",
       "      <td>0.553318</td>\n",
       "      <td>-0.209482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>796 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     principal component1  principal component2  principal component3  \\\n",
       "0                0.063927             -0.681744              0.053284   \n",
       "1                0.058611             -0.630972              0.127358   \n",
       "2                0.056012             -0.606144              0.163581   \n",
       "3                0.039158             -0.683262              0.053191   \n",
       "4                0.034175             -0.635663              0.122636   \n",
       "..                    ...                   ...                   ...   \n",
       "791              0.025624              0.696675              0.074157   \n",
       "792             -0.171061              0.993761              0.527883   \n",
       "793             -0.036974              0.794668              0.228558   \n",
       "794             -0.170018              0.992751              0.527118   \n",
       "795             -0.205687              1.027325              0.553318   \n",
       "\n",
       "     principal component4  \n",
       "0                0.082002  \n",
       "1               -0.069406  \n",
       "2               -0.143445  \n",
       "3                0.266411  \n",
       "4                0.124467  \n",
       "..                    ...  \n",
       "791             -0.569671  \n",
       "792             -0.238038  \n",
       "793             -0.458647  \n",
       "794             -0.238898  \n",
       "795             -0.209482  \n",
       "\n",
       "[796 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Floodfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data split\n",
    "## 8 : 2 으로 training 과 test 구분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(Floodfile, Floodclass , test_size=0.2, random_state=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "skfolds=StratifiedKFold(n_splits=5, random_state=400 ,shuffle = True)\n",
    "\n",
    "# 베이지안최적화과정에서 Kfold 를 사용하기위해 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "KNN_search_point = {'k': (3,20), 'leaf': (1,30)}  # 각 옵션들의 범위를 정해줌\n",
    "\n",
    "gp_params = {\"alpha\":1e-10}\n",
    "scores_all = []\n",
    "k_all = []\n",
    "leaf_all=[]\n",
    "\n",
    "def KNN_opt(k,leaf):\n",
    "    cvscores = []\n",
    "    \n",
    "    for train_index, val_index in skfolds.split(x_train, y_train):\n",
    "\n",
    "        x_skftrain, x_val = x_train.values[train_index], x_train.values[val_index]\n",
    "        Y_skftrain, Y_val = np.array(y_train)[train_index],np.array(y_train)[val_index]\n",
    "        # train 데이터를 5fold 를 사용해 검증하며 옵션 최적값 탐색을 위해 데이터 분할\n",
    "        \n",
    "        KNNmodel = KNeighborsClassifier(n_neighbors = int(k),weights = 'distance', leaf_size= leaf ) \n",
    "        # KNN 모델에 사용되는 옵션들의 최적값 탐색  \n",
    "        \n",
    "        KNNmodel2 = KNNmodel.fit(x_skftrain,Y_skftrain)        # 모델학습\n",
    "        y_pred = KNNmodel2.predict(x_val)                      # 예측\n",
    "\n",
    "        report = f1_score(Y_val, y_pred, average='weighted')  # F1\n",
    "        cvscores.append(report)                               # 결과들을 리스트로 저장\n",
    "    \n",
    "    \n",
    "    scores_all.append(np.mean(cvscores))\n",
    "    k_all.append(int(k))\n",
    "    \n",
    "    return np.mean(cvscores)\n",
    "\n",
    "result = BayesianOptimization(KNN_opt, KNN_search_point,    random_state=10,    verbose=2) \n",
    "result.maximize(acq='ucb',n_iter=15, kappa=2.576, init_points=1 , **gp_params)\n",
    "# 타겟과 범위를 정해준뒤에 그 결과를 확인 n_iter를 통해 확인 횟수 조절가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(k_all, scores_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN 과 동일 옵션만 바뀐 상태로 범위를 지정해주고 최적값을 탐색\n",
    "SVM_search_point = {'k': (1,30), 'gamma': (0.001,20)}\n",
    "\n",
    "gp_params = {\"alpha\":1e-10}\n",
    "scores_all = []\n",
    "k_all = []\n",
    "gamma_all = []\n",
    "\n",
    "def SVM_opt(k,gamma):\n",
    "    cvscores = []\n",
    "    \n",
    "    for train_index, val_index in skfolds.split(x_train, y_train):\n",
    "        \n",
    "        x_skftrain, x_val = x_train.values[train_index],x_train.values[val_index]\n",
    "        Y_skftrain, Y_val = np.array(y_train)[train_index],np.array(y_train)[val_index]\n",
    "\n",
    "        SVMmodel = SVC( C= 10 , kernel='rbf' , probability = True ) # SVM  \n",
    "        \n",
    "        SVMmodel2 = SVMmodel.fit(x_skftrain,Y_skftrain)      # 모델학습\n",
    "        y_pred = SVMmodel2.predict(x_val)                    # 예측\n",
    "\n",
    "        report = f1_score(Y_val, y_pred, average='weighted') # F1\n",
    "        cvscores.append(report)\n",
    "    \n",
    "    scores_all.append(np.mean(cvscores))\n",
    "    k_all.append(int(k))\n",
    "    return np.mean(cvscores)\n",
    "\n",
    "result = BayesianOptimization(SVM_opt, SVM_search_point, random_state=10, verbose=2) \n",
    "result.maximize(acq='ucb',n_iter=20, kappa=2.576, init_points=1 , **gp_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(k_all, scores_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_search_point = { 'k': (1,30), 'leaf' : ( 2, 30), 'split': (2,30) }\n",
    "\n",
    "gp_params = {\"alpha\":1e-10}\n",
    "scores_all = []\n",
    "k_all = []\n",
    "leaf_all = []\n",
    "split_all = []\n",
    "\n",
    "def DT_opt(k,leaf,split):\n",
    "    cvscores = []\n",
    "    \n",
    "    for train_index, val_index in skfolds.split(x_train, y_train):\n",
    "        x_skftrain, x_val = x_train.values[train_index],x_train.values[val_index]\n",
    "        Y_skftrain, Y_val = np.array(y_train)[train_index],np.array(y_train)[val_index]\n",
    "\n",
    "        DTmodel = DecisionTreeClassifier(criterion='gini',\n",
    "                                         max_depth=int(k), \n",
    "                                         min_samples_leaf= int(leaf),\n",
    "                                         min_samples_split= int(split)) #DT  \n",
    "        \n",
    "        \n",
    "        DTmodel2 = DTmodel.fit(x_skftrain,Y_skftrain)      # 모델학습\n",
    "        y_pred = DTmodel2.predict(x_val)                    # 예측\n",
    "\n",
    "        report = f1_score(Y_val, y_pred, average='weighted') # F1\n",
    "        cvscores.append(report)\n",
    "    \n",
    "    scores_all.append(np.mean(cvscores))\n",
    "    k_all.append(int(k))\n",
    "    leaf_all.append(int(leaf))\n",
    "    split_all.append(split)\n",
    "\n",
    "    \n",
    "    return np.mean(cvscores)\n",
    "\n",
    "result = BayesianOptimization(DT_opt, DT_search_point, random_state=10, verbose=2) \n",
    "result.maximize(acq='ucb',n_iter=15, kappa=2.576, init_points=1 , **gp_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(k_all, scores_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_search_point = { 'k': (1,50)}\n",
    "\n",
    "gp_params = {\"alpha\":1e-10}\n",
    "scores_all = []\n",
    "k_all = []\n",
    "\n",
    "def LR_opt(k):\n",
    "    cvscores = []\n",
    "    \n",
    "    for train_index, val_index in skfolds.split(x_train, y_train):\n",
    "        x_skftrain, x_val = x_train.values[train_index],x_train.values[val_index]\n",
    "        Y_skftrain, Y_val = np.array(y_train)[train_index],np.array(y_train)[val_index]\n",
    "\n",
    "        LRmodel = LogisticRegression(C= int(k) , multi_class= 'auto') #LR  \n",
    "        \n",
    "        \n",
    "        LRmodel2 = LRmodel.fit(x_skftrain,Y_skftrain)      # 모델학습\n",
    "        y_pred = LRmodel2.predict(x_val)                    # 예측\n",
    "\n",
    "        report = f1_score(Y_val, y_pred, average='weighted') # F1\n",
    "        cvscores.append(report)\n",
    "    \n",
    "    scores_all.append(np.mean(cvscores))\n",
    "    k_all.append(int(k))\n",
    "    \n",
    "    return np.mean(cvscores)\n",
    "\n",
    "result = BayesianOptimization(LR_opt, LR_search_point, random_state=10, verbose=2) \n",
    "result.maximize(acq='ucb',n_iter=20, kappa=2.576, init_points=1 , **gp_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(k_all, scores_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting ensemble\n",
    "## 사용 된 모델 : KNN, SVM, Decision Tree, Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_model = KNeighborsClassifier(n_neighbors = 11, weights = 'distance')\n",
    "\n",
    "SVM_model = SVC( C= 10 , kernel='rbf' , probability = True , gamma = 20 )\n",
    "\n",
    "DT_model = DecisionTreeClassifier(criterion='gini', max_depth=29, min_samples_leaf= 2, min_samples_split= 3)\n",
    "\n",
    "RF_model = RandomForestClassifier( n_estimators= 20,min_samples_split = 2, min_samples_leaf= 6, max_depth=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble=VotingClassifier(\n",
    "        estimators=[('KNN',KNN_model),\n",
    "                   ('SVM',SVM_model),\n",
    "                   ('DT',DT_model),\n",
    "                   ('RF',RF_model)]\n",
    "        ,voting='soft')\n",
    "\n",
    "# Voting 모델 안에 각 모델들을 묶어주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('KNN',\n",
       "                              KNeighborsClassifier(algorithm='auto',\n",
       "                                                   leaf_size=30,\n",
       "                                                   metric='minkowski',\n",
       "                                                   metric_params=None,\n",
       "                                                   n_jobs=None, n_neighbors=11,\n",
       "                                                   p=2, weights='distance')),\n",
       "                             ('SVM',\n",
       "                              SVC(C=10, break_ties=False, cache_size=200,\n",
       "                                  class_weight=None, coef0=0.0,\n",
       "                                  decision_function_shape='ovr', degree=3,\n",
       "                                  gamma=20, kernel='rbf', max_iter=-1,\n",
       "                                  probability=True, random_...\n",
       "                                                     criterion='gini',\n",
       "                                                     max_depth=15,\n",
       "                                                     max_features='auto',\n",
       "                                                     max_leaf_nodes=None,\n",
       "                                                     max_samples=None,\n",
       "                                                     min_impurity_decrease=0.0,\n",
       "                                                     min_impurity_split=None,\n",
       "                                                     min_samples_leaf=6,\n",
       "                                                     min_samples_split=2,\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     n_estimators=20,\n",
       "                                                     n_jobs=None,\n",
       "                                                     oob_score=False,\n",
       "                                                     random_state=None,\n",
       "                                                     verbose=0,\n",
       "                                                     warm_start=False))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='soft',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_model.fit(x_train,y_train)\n",
    "SVM_model.fit(x_train,y_train)\n",
    "DT_model.fit(x_train,y_train)\n",
    "RF_model.fit(x_train,y_train)\n",
    "ensemble.fit(x_train,y_train)\n",
    "\n",
    "# 각 모델에  train 데이터 학습시키고\n",
    "# 모델들이 묶어진 voting 앙상블에도 train 데이터를 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 교차검증 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKF = StratifiedKFold( n_splits = 5,  shuffle = True, random_state = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_scores=cross_validate(KNN_model, x_train, y_train, cv=SKF, scoring=make_scorer(f1_score))\n",
    "SVM_scores=cross_validate(SVM_model, x_train, y_train, cv=SKF, scoring=make_scorer(f1_score))\n",
    "DT_scores=cross_validate(DT_model, x_train, y_train, cv=SKF, scoring=make_scorer(f1_score))\n",
    "RF_scores=cross_validate(RF_model, x_train, y_train, cv=SKF, scoring=make_scorer(f1_score))\n",
    "ensemble_scores=cross_validate(ensemble, x_train, y_train, cv=SKF, scoring=make_scorer(f1_score))\n",
    "\n",
    "# 각 모델들의 성능 평가를 위해 교차검증 실시  확인할 score는 f1 임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([0.0019958 , 0.00199461, 0.00199437, 0.00199485, 0.00199437]), 'score_time': array([0.00199318, 0.00199485, 0.00199461, 0.00199509, 0.00199413]), 'test_score': array([0.7032967 , 0.7       , 0.79545455, 0.60674157, 0.75294118])}\n",
      "{'fit_time': array([0.02094364, 0.02098489, 0.02293444, 0.02094555, 0.02201557]), 'score_time': array([0.00199485, 0.00199628, 0.0010016 , 0.00192046, 0.00199294]), 'test_score': array([0.65263158, 0.64583333, 0.77083333, 0.64444444, 0.62650602])}\n",
      "{'fit_time': array([0.00199628, 0.00199485, 0.00199461, 0.00199485, 0.00299168]), 'score_time': array([0.00092292, 0.00199485, 0.00099707, 0.00099707, 0.00099778]), 'test_score': array([0.75      , 0.66666667, 0.65853659, 0.54117647, 0.68292683])}\n",
      "{'fit_time': array([0.02493286, 0.02692747, 0.02493119, 0.02493405, 0.02792454]), 'score_time': array([0.00299191, 0.00303221, 0.00299191, 0.00295448, 0.00299454]), 'test_score': array([0.69047619, 0.72916667, 0.72289157, 0.67368421, 0.70731707])}\n",
      "{'fit_time': array([0.05983973, 0.06183481, 0.05884242, 0.05983996, 0.05983996]), 'score_time': array([0.00698161, 0.00698137, 0.00698137, 0.00598407, 0.00598407]), 'test_score': array([0.7032967 , 0.70707071, 0.74418605, 0.60465116, 0.73170732])}\n"
     ]
    }
   ],
   "source": [
    "print(KNN_scores)\n",
    "print(SVM_scores)\n",
    "print(DT_scores)\n",
    "print(RF_scores)\n",
    "print(ensemble_scores)\n",
    "\n",
    "# validate 를 통해 모델 학습시간, 모델 가동시간, f1_score 를 확인 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score:  0.7117\n",
      "f1_score:  0.6680\n",
      "f1_score:  0.6599\n",
      "f1_score:  0.7047\n",
      "f1_score:  0.6982\n"
     ]
    }
   ],
   "source": [
    "KNN_f1_score = KNN_scores[\"test_score\"].mean()\n",
    "SVN_f1_score = SVM_scores[\"test_score\"].mean()\n",
    "DT_f1_score = DT_scores[\"test_score\"].mean()\n",
    "RF_f1_score = RF_scores[\"test_score\"].mean()\n",
    "ensemble_f1_score = ensemble_scores[\"test_score\"].mean()\n",
    "\n",
    "\n",
    "print(\"f1_score: {0: .4f}\".format(KNN_f1_score))\n",
    "print(\"f1_score: {0: .4f}\".format(SVN_f1_score))\n",
    "print(\"f1_score: {0: .4f}\".format(DT_f1_score))\n",
    "print(\"f1_score: {0: .4f}\".format(RF_f1_score))\n",
    "print(\"f1_score: {0: .4f}\".format(ensemble_f1_score))\n",
    "\n",
    "# 나온 값들의 평균을 확인을 위해 mean 값을 print로 표시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test 데이터 예측 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_KNN = KNN_model.predict(x_test)\n",
    "pred_SVM = SVM_model.predict(x_test)\n",
    "pred_DT = DT_model.predict(x_test)\n",
    "pred_RF = RF_model.predict(x_test)\n",
    "\n",
    "# 각 모델들의 test 데이터에 대한 예측 결과를 알기 위해 각각 예측실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict= ensemble.predict(x_test)\n",
    "\n",
    "# 적용 모델인 Voting ensemble 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 0.7068965517241379\n",
      "SVM 0.689655172413793\n",
      "DT 0.6491228070175438\n",
      "RF 0.7368421052631579\n",
      "Voting 0.6902654867256638\n"
     ]
    }
   ],
   "source": [
    "print('KNN',f1_score(y_test,pred_KNN))\n",
    "print('SVM',f1_score(y_test,pred_SVM))\n",
    "print('DT',f1_score(y_test,pred_DT))\n",
    "print('RF',f1_score(y_test,pred_RF))\n",
    "print('Voting',f1_score(y_test,y_predict))          # 각 모델들의 f1_Score 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020 년 사고사례 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "accident = pd.read_excel(\"초량동 지형 강우량.xlsx\")   # 초량지하차도 지형정보 와 당일 시간당 강우량 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Busanaccident = accident.drop(['SLOPE_L','SLOPE_H','FLOOD','MANHOLES_RATIO'], axis = 1)  # 불필요 컬럼제거\n",
    "Busanaccidentclass = accident['FLOOD']                                                   # 종속 변수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Busanaccident.rename(columns={'R_W_SUM':'Hourly_Rainfall_Weight','HOUR_RAINFALL':'Hourly_Rainfall','IMP_SUR_RATIO':'Impervious_Surface',\n",
    "                              'IMP_W_SUM':'Impervious_Surface_Weight'},inplace=True)  \n",
    "#가중치 적용을 위해 컬럼명 수정하여 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "accident = pd.read_excel(\"./초량동 지형 강우량.xlsx\")   # 초량지하차도 지형정보 와 당일 시간당 강우량 데이터\n",
    "accident\n",
    "\n",
    "Busanaccident = accident.drop(['SLOPE_L','SLOPE_H','FLOOD','MANHOLES_RATIO'], axis = 1)  # 불필요 컬럼제거\n",
    "Busanaccidentclass = accident['FLOOD']                                                   # 종속 변수 \n",
    "\n",
    "Busanaccident.rename(columns={'R_W_SUM':'Hourly_Rainfall_Weight','HOUR_RAINFALL':'Hourly_Rainfall','IMP_SUR_RATIO':'Impervious_Surface',\n",
    "                              'IMP_W_SUM':'Impervious_Surface_Weight'},inplace=True)  \n",
    "#가중치 적용을 위해 컬럼명 수정하여 사용\n",
    "\n",
    "Busanaccident['SLOPE_AVG'] = Busanaccident['SLOPE_AVG'].astype(float)\n",
    "Busanaccident['HIGH'] = Busanaccident['HIGH'].astype(float)\n",
    "\n",
    "rain_weight = Busanaccident['Hourly_Rainfall'].copy()\n",
    "imp_weight = Busanaccident['Impervious_Surface'].copy()\n",
    "slope_weight = Busanaccident['SLOPE_AVG'].copy()\n",
    "high_weight = Busanaccident['HIGH'].copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 강우량 가중치\n",
    "\n",
    "for idx,col in enumerate(Busanaccident['Hourly_Rainfall']):\n",
    "    if col <= 15:\n",
    "        rain_weight[idx] = col / (46)\n",
    "    elif col > 15 and col <= 35:\n",
    "        rain_weight[idx] = col / (18 * 2**2)\n",
    "    elif col > 35 and col <= 60:\n",
    "        rain_weight[idx] = col / (17 * 3**2)\n",
    "    elif col > 60 and col <= 80:\n",
    "        rain_weight[idx] = col / (11 * 4**2)\n",
    "    elif col > 80:\n",
    "        rain_weight[idx] = col / (6.28 * 5**2)\n",
    "\n",
    "## 불투수면 가중치\n",
    "\n",
    "for idx,col in enumerate(Busanaccident['Impervious_Surface']):\n",
    "    if col <= 15:\n",
    "        imp_weight[idx] = col / 6.66\n",
    "    elif col > 15 and col <= 25:\n",
    "        imp_weight[idx] = col / (20 * 2)\n",
    "    elif col > 25 and col <= 40:\n",
    "        imp_weight[idx] = col / (13.33 * 3)\n",
    "    elif col > 40 and col <= 55:\n",
    "        imp_weight[idx] = col / (33.33 * 4)\n",
    "    elif col > 55:\n",
    "        imp_weight[idx] = col / (26.67 * 5)\n",
    "\n",
    "## 경사도 가중치\n",
    "\n",
    "#Busanaccident['SLOPE_AVG_Weight'] = Busanaccident['SLOPE_AVG']\n",
    "\n",
    "for idx,col in enumerate(Busanaccident['SLOPE_AVG']):\n",
    "    if col <= 10:\n",
    "        slope_weight[idx] = col / (41.67 / 5**2 )\n",
    "    elif col > 10 and col <= 15:\n",
    "        slope_weight[idx] = col / (25 / 4**2)\n",
    "    elif col > 15 and col <= 25:\n",
    "        slope_weight[idx] = col / (16.67 / 3**2)\n",
    "    elif col > 25 and col <= 50:\n",
    "        slope_weight[idx] = col / (8.33 / 2**2)\n",
    "    elif col > 50:\n",
    "        slope_weight[idx] = col / (8.33 / 1**2)\n",
    "\n",
    "## 고도 가중치\n",
    "\n",
    "#Busanaccident['HIGH_Weight'] = Busanaccident['HIGH']\n",
    "\n",
    "for idx,col in enumerate(Busanaccident['HIGH']):\n",
    "    if col <= 20:\n",
    "        high_weight[idx] = col / (79.62 / 1**2)\n",
    "    elif col > 20 and col <= 40:\n",
    "        high_weight[idx] = col / (10.18 / 2**2)\n",
    "    elif col > 40 and col <= 60:\n",
    "        high_weight[idx] = col / (4.63 / 3**2)\n",
    "    elif col > 60 and col <= 80:\n",
    "        high_weight[idx] = col / (2.78 / 4**2)\n",
    "    elif col > 80:\n",
    "        high_weight[idx] = col / (2.78 / 5**2)\n",
    "\n",
    "slope_weight\n",
    "\n",
    "Busanaccident['Hourly_Rainfall_Weight'] = rain_weight\n",
    "Busanaccident['Impervious_Surface_Weight'] = imp_weight\n",
    "Busanaccident['SLOPE_AVG_Weight'] = slope_weight\n",
    "Busanaccident['HIGH_Weight'] = high_weight\n",
    "\n",
    "\n",
    "## 가중치 값을 구한뒤 불필요한 변수 다시 제거\n",
    "\n",
    "Busanaccident = Busanaccident.drop(['SLOPE_AVG','Impervious_Surface','Hourly_Rainfall','HIGH'], axis = 1)\n",
    "\n",
    "Busanaccident\n",
    "\n",
    "Busanaccident = Busanaccident[['Hourly_Rainfall_Weight','Impervious_Surface_Weight','SLOPE_AVG_Weight','HIGH_Weight','F_WEIGHT','PUMP_RATIO']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hourly_Rainfall_Weight</th>\n",
       "      <th>Impervious_Surface_Weight</th>\n",
       "      <th>SLOPE_AVG_Weight</th>\n",
       "      <th>HIGH_Weight</th>\n",
       "      <th>F_WEIGHT</th>\n",
       "      <th>PUMP_RATIO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.434346</td>\n",
       "      <td>0.599952</td>\n",
       "      <td>0.050239</td>\n",
       "      <td>0.017</td>\n",
       "      <td>1.982160e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.434346</td>\n",
       "      <td>0.599952</td>\n",
       "      <td>0.050239</td>\n",
       "      <td>0.017</td>\n",
       "      <td>1.982160e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.434346</td>\n",
       "      <td>0.599952</td>\n",
       "      <td>0.050239</td>\n",
       "      <td>0.017</td>\n",
       "      <td>1.982160e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.434346</td>\n",
       "      <td>0.599952</td>\n",
       "      <td>0.050239</td>\n",
       "      <td>0.017</td>\n",
       "      <td>1.982160e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.434346</td>\n",
       "      <td>0.599952</td>\n",
       "      <td>0.050239</td>\n",
       "      <td>0.017</td>\n",
       "      <td>1.982160e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.434346</td>\n",
       "      <td>0.599952</td>\n",
       "      <td>0.050239</td>\n",
       "      <td>0.017</td>\n",
       "      <td>1.982160e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.434346</td>\n",
       "      <td>0.599952</td>\n",
       "      <td>0.050239</td>\n",
       "      <td>0.017</td>\n",
       "      <td>1.982160e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.434346</td>\n",
       "      <td>0.599952</td>\n",
       "      <td>0.050239</td>\n",
       "      <td>0.017</td>\n",
       "      <td>1.982160e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.076087</td>\n",
       "      <td>0.434346</td>\n",
       "      <td>0.599952</td>\n",
       "      <td>0.050239</td>\n",
       "      <td>0.017</td>\n",
       "      <td>1.982160e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.434346</td>\n",
       "      <td>0.599952</td>\n",
       "      <td>0.050239</td>\n",
       "      <td>0.017</td>\n",
       "      <td>1.982160e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.434346</td>\n",
       "      <td>0.599952</td>\n",
       "      <td>0.050239</td>\n",
       "      <td>0.017</td>\n",
       "      <td>1.982160e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.434346</td>\n",
       "      <td>0.599952</td>\n",
       "      <td>0.050239</td>\n",
       "      <td>0.017</td>\n",
       "      <td>1.982160e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.434346</td>\n",
       "      <td>0.599952</td>\n",
       "      <td>0.050239</td>\n",
       "      <td>0.017</td>\n",
       "      <td>1.982160e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.434346</td>\n",
       "      <td>0.599952</td>\n",
       "      <td>0.050239</td>\n",
       "      <td>0.017</td>\n",
       "      <td>1.982160e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.434346</td>\n",
       "      <td>0.599952</td>\n",
       "      <td>0.050239</td>\n",
       "      <td>0.017</td>\n",
       "      <td>1.982160e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.141304</td>\n",
       "      <td>0.434346</td>\n",
       "      <td>0.599952</td>\n",
       "      <td>0.050239</td>\n",
       "      <td>0.017</td>\n",
       "      <td>1.982160e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.434346</td>\n",
       "      <td>0.599952</td>\n",
       "      <td>0.050239</td>\n",
       "      <td>0.017</td>\n",
       "      <td>1.982160e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.434346</td>\n",
       "      <td>0.599952</td>\n",
       "      <td>0.050239</td>\n",
       "      <td>0.017</td>\n",
       "      <td>1.982160e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.141304</td>\n",
       "      <td>0.434346</td>\n",
       "      <td>0.599952</td>\n",
       "      <td>0.050239</td>\n",
       "      <td>0.017</td>\n",
       "      <td>1.982160e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.282609</td>\n",
       "      <td>0.434346</td>\n",
       "      <td>0.599952</td>\n",
       "      <td>0.050239</td>\n",
       "      <td>0.017</td>\n",
       "      <td>1.982160e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.434346</td>\n",
       "      <td>0.599952</td>\n",
       "      <td>0.050239</td>\n",
       "      <td>0.017</td>\n",
       "      <td>1.982160e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.434346</td>\n",
       "      <td>0.599952</td>\n",
       "      <td>0.050239</td>\n",
       "      <td>0.017</td>\n",
       "      <td>1.982160e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.411932</td>\n",
       "      <td>0.434346</td>\n",
       "      <td>0.599952</td>\n",
       "      <td>0.050239</td>\n",
       "      <td>0.017</td>\n",
       "      <td>1.982160e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.163043</td>\n",
       "      <td>0.434346</td>\n",
       "      <td>0.599952</td>\n",
       "      <td>0.050239</td>\n",
       "      <td>0.017</td>\n",
       "      <td>1.982160e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.163043</td>\n",
       "      <td>0.434346</td>\n",
       "      <td>0.599952</td>\n",
       "      <td>0.050239</td>\n",
       "      <td>0.017</td>\n",
       "      <td>1.982160e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.434346</td>\n",
       "      <td>0.599952</td>\n",
       "      <td>0.050239</td>\n",
       "      <td>0.017</td>\n",
       "      <td>1.982160e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.434346</td>\n",
       "      <td>0.599952</td>\n",
       "      <td>0.050239</td>\n",
       "      <td>0.017</td>\n",
       "      <td>1.982160e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.434346</td>\n",
       "      <td>0.599952</td>\n",
       "      <td>0.050239</td>\n",
       "      <td>0.017</td>\n",
       "      <td>1.982160e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Hourly_Rainfall_Weight  Impervious_Surface_Weight  SLOPE_AVG_Weight  \\\n",
       "0                 0.000000                   0.434346          0.599952   \n",
       "1                 0.000000                   0.434346          0.599952   \n",
       "2                 0.000000                   0.434346          0.599952   \n",
       "3                 0.000000                   0.434346          0.599952   \n",
       "4                 0.010870                   0.434346          0.599952   \n",
       "5                 0.000000                   0.434346          0.599952   \n",
       "6                 0.000000                   0.434346          0.599952   \n",
       "7                 0.021739                   0.434346          0.599952   \n",
       "8                 0.076087                   0.434346          0.599952   \n",
       "9                 0.000000                   0.434346          0.599952   \n",
       "10                0.010870                   0.434346          0.599952   \n",
       "11                0.010870                   0.434346          0.599952   \n",
       "12                0.010870                   0.434346          0.599952   \n",
       "13                0.010870                   0.434346          0.599952   \n",
       "14                0.021739                   0.434346          0.599952   \n",
       "15                0.141304                   0.434346          0.599952   \n",
       "16                0.173913                   0.434346          0.599952   \n",
       "17                0.108696                   0.434346          0.599952   \n",
       "18                0.141304                   0.434346          0.599952   \n",
       "19                0.282609                   0.434346          0.599952   \n",
       "20                0.173913                   0.434346          0.599952   \n",
       "21                0.333333                   0.434346          0.599952   \n",
       "22                0.411932                   0.434346          0.599952   \n",
       "23                0.163043                   0.434346          0.599952   \n",
       "24                0.163043                   0.434346          0.599952   \n",
       "25                0.000000                   0.434346          0.599952   \n",
       "26                0.000000                   0.434346          0.599952   \n",
       "27                0.000000                   0.434346          0.599952   \n",
       "\n",
       "    HIGH_Weight  F_WEIGHT    PUMP_RATIO  \n",
       "0      0.050239     0.017  1.982160e-07  \n",
       "1      0.050239     0.017  1.982160e-07  \n",
       "2      0.050239     0.017  1.982160e-07  \n",
       "3      0.050239     0.017  1.982160e-07  \n",
       "4      0.050239     0.017  1.982160e-07  \n",
       "5      0.050239     0.017  1.982160e-07  \n",
       "6      0.050239     0.017  1.982160e-07  \n",
       "7      0.050239     0.017  1.982160e-07  \n",
       "8      0.050239     0.017  1.982160e-07  \n",
       "9      0.050239     0.017  1.982160e-07  \n",
       "10     0.050239     0.017  1.982160e-07  \n",
       "11     0.050239     0.017  1.982160e-07  \n",
       "12     0.050239     0.017  1.982160e-07  \n",
       "13     0.050239     0.017  1.982160e-07  \n",
       "14     0.050239     0.017  1.982160e-07  \n",
       "15     0.050239     0.017  1.982160e-07  \n",
       "16     0.050239     0.017  1.982160e-07  \n",
       "17     0.050239     0.017  1.982160e-07  \n",
       "18     0.050239     0.017  1.982160e-07  \n",
       "19     0.050239     0.017  1.982160e-07  \n",
       "20     0.050239     0.017  1.982160e-07  \n",
       "21     0.050239     0.017  1.982160e-07  \n",
       "22     0.050239     0.017  1.982160e-07  \n",
       "23     0.050239     0.017  1.982160e-07  \n",
       "24     0.050239     0.017  1.982160e-07  \n",
       "25     0.050239     0.017  1.982160e-07  \n",
       "26     0.050239     0.017  1.982160e-07  \n",
       "27     0.050239     0.017  1.982160e-07  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Busanaccident"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정리된 데이터에 scale 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(Busanaccident)\n",
    "Busanaccident = scaler.transform(Busanaccident)                         # sccler 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 데이터와 동일한 데이터 형태로 만들기위해 pca사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=4)\n",
    "printcipalComponents = pca.fit_transform(Busanaccident)\n",
    "Busanaccident = pd.DataFrame(data=printcipalComponents, columns = ['principal component1', 'principal component2','principal component3', 'principal component4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 초량동에 대한 예측 실시\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "accident_predict= ensemble.predict(Busanaccident)                       # 학습된 모델을 활용해 사고사례 예측 실시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(accident_predict)                                                 # 예측값 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
